<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>DL final project</title>

    <meta name="author" content="Joy He-Yueya">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Propaganda Dectection Using BERT</name>
                        </p>
                        <p>Group members: Pemi Nguyen, Joy He, Fengyuan Liu, and Lily Zhao
                        </p>
                    </td>
                    <!--             <td style="padding:2.5%;width:40%;max-width:40%">
                                  <a href="images/joyheyueya.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/joyheyueya.jpg" class="hoverZoomLink"></a>
                                </td> -->
                </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Abstract</heading>
                        <p>
                            Propaganda contains all types of false, inaccurate or misleading information about individuals,
                            historical events, social issues, etc. and pose a big threat to our society. In today's world,
                            there’s a lot of widespread propaganda on different social media and online platforms, and it’s not easy to distinguish propagandistic content from non-propagandistic content from the untrained human eyes. In this project, we fine-tuned a BERT pretrained model and trained on a large corpus of non-propagandistic and propagandistic news and compared it with a baseline Naive Bayes classifier in order to see how well it is able to classify news as propagandistic or non-propagandistic. Our results found that while both models achieved roughly similarly high overall accuracy and high true negative rate (correctly identifying a non-propagandistic news as one), the BERT fine-tuned model has a 16.4% larger true positive rate (correctly identifying a propagandistic news as one). This promising result shows that BERT has the potential to detect propaganda well and lays a foundation for future work in building propaganda or fake news classifiers.
                        </p>
                            <img src="propaganda.png" width="745" height="447">
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                </tbody>
            </table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Problem statement</heading>
                        <p>
                            Misinformation and propaganda have become a major concern in society nowadays. The sheer volume of information coming from various sources, especially with the rise of social media where people have more platforms to share information, has directly contributed to an influx of misinformation. Propaganda is biased information that propagates a particular ideology or political
                            orientation, which might
                            have negative impacts on individuals and society (e.g., the US Presidential campaign in 2016
                            was influenced
                            by propaganda and fake news). Propagandistic content is often spread widely social media platforms like Facebook or Twitter and share a lot of similar linguistic characteristics such as excessive use of hyperbolic or unsubstantiated claims. It is difficult to spot propaganda with untrained human eyes
                            because propaganda
                            is not necessarily misinformtion. The development of machine learning has also led to the emergence of "neural fake news", a kind of misinformation generated by machines but greatly mimics human style, thus is more difficult to discern. To combat propaganda, we can harness the power of state-of-the-art NLP deep learning models such as BERT in order to recognize whether an article contains propagandistic content or not. Our goal is to build a propaganda classifier that aims to
                            detect whether
                            an online article from a website is "propagandistic" (positive class) or
                            "non-propagandistic" (negative class).
                            The labeling was done indirectly using <a
                                href="https://zenodo.org/record/3271522#.X9m6Hy2cZo5">distant
                            supervision</a>, where an article is considered propagandistic if it comes from a news
                            outlet that is labeled
                            as propagandistic by human annotators.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Related work</heading>
                        <p>
                            Previous work on propaganda detection has focused on using word n-gram representation as
                            features for machine learning models. <a
                                href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjagYrYvdTtAhWS3YUKHbt8AFoQFjAAegQIAhAC&url=https%3A%2F%2Fwww.aclweb.org%2Fanthology%2FD17-1317&usg=AOvVaw2CML3xIxQK7tMLmqZ2OTbQ">Rashkin
                            et al.</a> formulated a text classification task (propaganda vs. trusted) using n-grams with
                            a logistic regression model, which led to poor performance on articles outside the sources
                            that the system was trained on. <a
                                href="https://www.sciencedirect.com/science/article/abs/pii/S0306457318306058">Barron et
                            al.</a> experimented with various features, from writing style and readability level to the
                            presence of certain keywords, and also used logistic regression models as well as SVMs.
                            Other studies have looked into detecting common propaganda techniques such as name calling
                            (i.e., attacking an object/subject of the propaganda with an insulting label), repetition
                            (i.e., repeating the same message over and over), and slogans (i.e., using a brief and
                            memorable phrase). <a href="https://www.aclweb.org/anthology/D19-1565/">Da San Martino et
                            al.</a> proposed a multi-granularity deep neural network that predicts where a propaganda
                            technique is used in a piece of text as well as the type of technique. Their best-performing
                            models for this task used <a href="https://arxiv.org/abs/1810.04805">BERT</a>-based
                            contextual representations. <a
                                href="https://arxiv.org/pdf/2006.00593.pdf?fbclid=IwAR0EJp_Uhq9T5Gh2R1TPeQrvYmoNjb72PNWtsJKpIk998FX1vdFMORInbA0">Agarwal
                            et al.</a> built on their work by developing an ensembled model combining linguistic
                            features-based machine learning classifiers with these transformer models.
                        </p>

                        <p>
                            <a href="https://arxiv.org/abs/1810.04805">BERT</a> (Bidirectional Encoder Representations from Transformers), released in late 2018, is a method of pretraining language representations that was used to create models that NLP practitioners can then download and use for free. These models can then be used to extract high quality language features from raw text data or can be fine-tuned on a specific task (classification, entity recognition, question answering, etc.) with a different dataset to produce state-of-the-art predictions.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Dataset</heading>
                        <p>
                            For our dataset, we used <a href="https://zenodo.org/record/3271522#.X9m6Hy2cZo5">Propaganda Analysis Project</a>. This corpus contains 52k articles from 100+ news outlets. Each article is
                            labeled as either “propagandistic” or “non-propagandistic”. The labeling was done indirectly
                            using <a href="https://zenodo.org/record/3271522#.X9m6Hy2cZo5">distant supervision</a> with
                            information from <a href="http://mediabiasfactcheck.com">Media Bias/Fact Check (MBFC)</a>,
                            which is an independent organization evaluating media in terms of their bias and
                            propagandistic content. The organization is composed of expert journalists or volunteers who
                            analyze entire news outlets. An article is considered propagandistic if it comes from a news
                            outlet that is labeled as propagandistic by these expert annotators.
                        </p>

                        <p>
                          There are three files in this dataset:
                          <ul>
                            <li> <i>proppy_1.0.train.tsv</i>: 35986 articles in total, including 31965 real ones (88.82 %) and 4021 propagandistic ones (11.18 %). This file is used for training.
                            </li>
                            <li> <i>proppy_1.0.dev.tsv</i>: 5125 articles in total, including 4550 real ones (88.78 %) and 575 propagandistic ones (11.22 %). This file is used for validation.
                            </li>
                            <li> <i>proppy_1.0.test.tsv</i>: 10159 articles in total, including 9019 real ones (88.78 %) and 1140 propagandistic ones (11.22 %). This file is used for testing.
                            </li>                                       
                          </ul>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Methodology</heading>
                        <ol>
                          <li><strong>Fine-tuned BERT</strong></li>
                        <p>
                          Our approach used BERT to train a text classifier. Specifically, we took the pre-trained BERT model and added a few connected layers on top (with ReLU and Dropout) and trained the new model for our propaganda classification task. Fine-tuning BERT has three advantages over training a specific deep learning model (e.g., CNN and BiLSTM) that is well suited specific NLP tasks:
                        <ul>
                            <li><strong>Quicker Development</strong>: 
                            The pre-trained BERT model weights already encode a lot of information about our language, so it takes a lot less time to train the fine-tuned model. The authors recommend only 2-4 epochs for fine-tuning BERT, which saves a lot of time, compared to having to train models from scratch.
                            </li>
                            <li><strong>Less Data</strong>: When we train models from scratch, we usually need extremely massive datasets in order to train our network to a decent accuracy. However, large datasets might not be always available. BERT allows us to use its pre-trained weights and fine-tune it to work on different NLP problems with much smaller data.
                            </li>
                            <li><strong>Better Results</strong>: This simple fine-tuning procedure (typically adding one fully-connected layer on top of BERT and training for a few epochs) was shown to achieve state-of-the-art results with minimal task-specific adjustments for a wide variety of tasks: classification, language inference, semantic similarity, question answering, etc.
                            </li>
                        </ul>
                        </p>

                        <p>
                            We will discuss specific implementation details in the following.
                        </p>

                        <ol type="a">
                          <li>
                            Text preprocesssing
                          </li>
                            <p>
                            We first processed and cleaned our raw data. We removed entity mentions (e.g., @united) and some special characters. The level of processing here is much less than regular NLP models, because BERT was trained with the entire sentences.
                            </p>

                          <li>
                            BERT tokenization
                          </li>
                            <p>
                              To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary. We use the tokenizer bert-base-uncased from the huggingface library.
                            </p>
                            <p>
                              For each article, the BERT tokenizer allows us to:
                              <ul>
                                <li>
                                  Split it into tokens and map them to their IDs corresponding to the tokenizer vocabulary
                                </li>
                                <li>
                                  Pad or truncate all articles to the same length. The maximum length for the BERT model is 512. As a result, if an article is less than 512, we have to pad extra 0s to the end. Otherwise, if an article is greater than 512, we decided to only process the first 512 words of each article. This is because the main content of each article seems to be always in the beginning and play a great role in determining the overall content of an article. We don’t need to look beyond the first 512 words to be more certain about whether an article is propagandistic or not.
                                </li>
                                <li>
                                  Add the special `[CLS]` and `[SEP]` tokens to the beginning and the end of each article. The [CLS] token is added at the beginning of the input sequence for classification tasks. The [SEP] token marks the end of a sentence, which allows the model to determine where a sentence ends, which is often used in next sentence prediction tasks. However, for simplicity, we will consider that each article is a big long sentence. Thus the [SEP] token will be added to the end of the sentence.
                                </li>
                                <li>
                                  Create the attention masks which explicitly differentiate real tokens from the padded 0s.
                                </li>
                              </ul>
                            </p>
                          <li>
                            Creating a model
                          </li>
                            <p>
                              Bert-base-uncased model consists of 12 transformer layers. Each transformer layer takes in a list of token embeddings, and produces the same number of embeddings with the same hidden size (or dimensions) on the output. The output of the final transformer layer of the [CLS] token is used as the features of the sequence to feed a classifier. We extracted the last hidden layer of the [CLS] token and fed it to a classifier consisting of a hidden layer, a ReLU, a Dropout and a final layer of size 2, because we have 2 classes for the output.
                            </p>

                          <li>
                            Training the model
                          </li>
                            <p>
                              To optimize the performance of the model, we use the AdamW algorithm, which <a href="https://arxiv.org/abs/1711.05101">Loshchilov and Hutter</a> claimed that it yields better training loss and yields more generalizable models than the Adam one. There are a number of hyperparameters, such as batch size, learning rate, number of epochs. However, we observed that the learning rate seemed to make the most difference to the model’s performance on the validation set. As a result, we chose a number of small learning rates, such as 2e-6, 5e-6, 2e-5, 5e-5.
                            </p>
                            <p>
                              When observing the performance of the model during training, we see that the train loss reaches near 0 and the train accuracy reaches near 100% within just a small number of epochs. There might be a sign that the model is prone to overfitting, as the validation loss keeps increasing in later epochs (it is supposed to decrease). However, we observed that the validation accuracy increases in later epochs (even though it didn’t increase much, since the validation accuracies on earlier epochs are already very high). Thus, we believe that the validation loss might not be a good indicator of the performance of the BERT model on the validation set. Thus, to determine the best model, we chose the weights that resulted in the largest validation accuracy instead of the one that resulted in the smallest validation loss as usual.
                            </p>
                            <p>
                              We fine-tuned our hyperparameters and eventually chose a batch size of 8, a learning rate of 2e-5, and 10 epochs.
                            </p>
                        </ol>

                        <li><strong>Baseline: Naive Bayes with TF-IDF vectorization</strong></li>
                        <p> In order to check how well the BERT model does compare to other NLP models, we chose a Naive Bayes classifier with TF-IDF vectorization as our baseline.
                        </p>

                        <p> Naive Bayes classifiers are linear classifiers known for being easy to implement. Naive Bayes naively assumes that each word in a text occurs independently of its surrounding words. In practice, this independence assumption is usually violated, because words are not mutually independent. However, this model is able to achieve standard accuracies on a lot of NLP problems. In <a href="https://hrashkin.github.io/publications/factcheck_emnlp17.pdf">Rashkin et al</a>’s research on fake news detection and political fact-checking using a Politico dataset, the Naive Bayes model yielded the highest tech accuracy for text classification on 2 classes together with a LSTM one (56 %).
                        </p>

                        <ol type="a">
                          <li>Text preprocessing</li>
                          <p>
                            Before feeding the texts into the classifier, we had to do a lot of text preprocessing to make the sentences lowercase, remove punctuations, remove stop words, etc.
                          </p>
                          <li>TF-IDF vectorizer</li>
                          <p>
                            We then used the TF-IDF (term frequency-inverse document frequency) weighting scheme in order to vectorize the texts. This weighting scheme is very popular in information retrieval and machine learning. It is a measure of originality of word, by comparing the number of times a word appears in a document versus the number of documents it appears in. Words that appear a lot in every single document and across many documents, such as “the” or “what”, are not very informative and don't contribute much to the meaning of the article. On the other hand, if a word appears more frequently in a specific document, it suggests this certain word is uniquely important to that document.
                          </p>
                          <li>Training the Naive Bayes classifier</li>
                          <p>
                            We used the MultinomialNB() algorithm from sklearn. The only hyperparameter that we had to fine-tune is alpha, the Laplace smoothing parameter. We checked the result of the model on various alpha values between 0 and 1, and found that when alpha = 2e-3 the model gave the highest validation accuracy. After getting the best hyperparameter, we test its performance on the test set.
                          </p>
                        </ol>
                      </ol>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Experiments / Evaluation</heading>
                        <p>
                            We trained our models on the training set until the validation loss stops increasing. Then,
                            we ran all the models on the test set to get a final test accurracy, and then in the end, we
                            will run all the models with a test set to check the final test accuracy.
                            To evaluate our model, we built a baseline model, which is a Naive Bayes classifier.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Results</heading>
                        <ol>
                          <li><strong>Fine-tuned BERT</strong></li>

                        <p>
                          The train losses, validation losses, train accuracies and validation accuracies of the Fine-tuned BERT model are demonstrated in the plots below:
                        </p>
                            <img src="bert_loss.png" width="600" height="200" class="center">   

                            <img src="bert_acc.png" width="600" height="200" class="center">  

                        <p>
                          The table below shows the performance of the Fine-tuned BERT model.
                        </p>
                            <img src="bert_table.png" width="600" height="220" class="center"> 

                        <p>
                            The figure below shows the confusion matrix for the BERT model.
                        </p>

                            <img src="bert_confusion.png" width="600" height="300" class="center">    

                          <li><strong>Naive Bayes classifier</strong>
                          </li>
                        <p>
                          The table below shows the performance of the Naive Bayes classifier.
                        </p>
                            <img src="nb_table.png" width="600" height="220" class="center">                        
                        <p> The figure below is the confusion matrix for the Naive Bayes classifier.
                        </p>

                            <img src="nb_confusion.png" width="600" height="300" class="center">                            
                        <p> The test accuracies for both models are roughly close and very high (95.46% for the Naive Bayes model and 97.41% for the fine-tuned BERT model). However, purely looking at this doesn’t allow us to have a full picture of how well these two models perform. Due to the imbalance proportion of propagandistic articles in the original dataset (about 11% across 3 data files), both models might have learned the features of a non-propagandistic article well, and the classification result is skewed towards the non-propagandistic class. As a result, both models have very high true negative rates, which are close to 100%. This suggests that they both don’t have difficulty identifying articles free of propagandistic content. However, when looking at the true positive rate, we can see that the Naive Bayes model doesn’t do as well as the fine-tuned BERT one. BERT seems to be able to extract features of propagandistic content in an article and learn to differentiate it with unbiased, neutral content.
                        </p>

                        <p>
                          It’s worth noting that the true positive rates from both models are not as not as good their respective true negative rates, which seems to suggest that NLP models, even the classic ones, are able to correctly evaluate non-propagandistic content with very high probability, but propagandistic content still poses a challenge to them. 
                        </p>
                      </ol>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Conclusion</heading>
                        <p>
                          The performance of BERT fine-tuned model on detecting articles with propagandistic content is much better than the baseline Naive Bayes model. Detecting these kinds of texts is not even an easy task even for humans, but the results from BERT shows promising results that it can be harnessed to make good predictions and utilized to combat fake news and propaganda nowadays.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Video</heading>
                        <p>
                            Here's our demo for the <a href="https://www.youtube.com/watch?v=k-ZKOeZTWKg">BERT classifier</a>.
                        </p>
<!--                         <iframe width="745" height="447"
                          src="https://www.youtube.com/watch?v=MFJ4DJw7N2M">
                        </iframe> -->

                        <p>
                          And here's one for our baseline model, a <a href="https://www.youtube.com/watch?v=dO8jofstGq8">Naive Bayes classifier</a>.
                        </p>
<!--                         <iframe width="745" height="447"
                          src="https://www.youtube.com/watch?v=5DISI3SyjaY">
                        </iframe>    -->                     
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                </tbody>
            </table>
</body>

</html>
